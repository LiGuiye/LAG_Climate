{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Models for Extreme Geospatial Downscaling\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-LAG_Climate-white.svg)](https://github.com/LiGuiye/LAG_Climate) [![Paper](https://img.shields.io/badge/Paper-arxiv.2402.14049-B31B1B.svg)](https://arxiv.org/abs/2402.14049) [![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LiGuiye/LAG_Climate/blob/main/test.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Clone LAG_Climate from GitHub and install requirements (for Google Colab)\n",
    "!git clone https://github.com/LiGuiye/LAG_Climate.git\n",
    "%cd LAG_Climate\n",
    "!pip install \"git+https://github.com/dsc/bunch.git\" # most requiremets are already installed in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import Libraries and functions for plotting\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from data.config import get_dataset_path\n",
    "from nets.dataset import get_dataset\n",
    "from nets.models import Generator\n",
    "from utils.utils import set_random_seed, get_config_from_json, upscale, normalize, downscale\n",
    "\n",
    "\n",
    "def load_dataset(args):\n",
    "    (path_train, path_test, train_mean, train_std) = get_dataset_path(args.data_name)\n",
    "    args.train_mean = [float(i) for i in train_mean.split(',')]\n",
    "    args.train_std = [float(i) for i in train_std.split(',')]\n",
    "    dataset_test = get_dataset(path_test, args.data_size, args.train_mean, args.train_std)\n",
    "    return dataset_test, args\n",
    "\n",
    "\n",
    "def load_gen(args, curr_scale, device = torch.device(\"cuda\")):\n",
    "    g_ema = Generator(\n",
    "        args.channel,\n",
    "        args.noise_dim,\n",
    "        kernelSize=args.kernelSize,\n",
    "        residual_blocks=args.residual_blocks,\n",
    "        residual_scaling=args.residual_scaling\n",
    "    ).to(device)\n",
    "    checkpoint = torch.load(f\"{args.expid}/checkpoint/LAG_scale_{curr_scale}.pt\", map_location=device)#, weights_only=True)\n",
    "    g_ema.load_state_dict(checkpoint['gen_ema_state_dict'])\n",
    "    return g_ema\n",
    "\n",
    "\n",
    "def pred_img(args, dataset, idx:list, curr_scale:int, model, ncand:int=3, forceCPU:bool=True):\n",
    "    samples_list = [dataset[i] for i in idx]\n",
    "    hires = torch.stack(samples_list).to(torch.device(\"cuda\"))\n",
    "    lores = upscale(hires, args.max_scale)\n",
    "    hires = upscale(hires, args.max_scale // curr_scale)\n",
    "\n",
    "    n, _, h, w = lores.shape\n",
    "    eps_size = [n, args.noise_dim, h, w]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = torch.cat(\n",
    "            [\n",
    "                model(\n",
    "                    lores,\n",
    "                    torch.normal(\n",
    "                        mean=0,\n",
    "                        std=y / (ncand - 1) if ncand > 1 else 0,\n",
    "                        size=eps_size,\n",
    "                        device=torch.device(\"cuda\")\n",
    "                    ),\n",
    "                    curr_scale, 1\n",
    "                )\n",
    "                for y in range(ncand)\n",
    "            ],\n",
    "            dim=3\n",
    "        )\n",
    "\n",
    "    # stretch to origianl data range\n",
    "    hires = normalize(hires, args.train_mean, args.train_std, True)\n",
    "    lores = upscale(hires, curr_scale)\n",
    "    fake = normalize(fake, args.train_mean, args.train_std, True)\n",
    "\n",
    "    prepReturn = lambda x: x.cpu().squeeze() if forceCPU else x.squeeze()\n",
    "\n",
    "    return prepReturn(hires), prepReturn(lores), prepReturn(fake)\n",
    "\n",
    "\n",
    "def plot_preds(args, g_ema, dataset, curr_scale:int, idx:list=[0], ncand:int=3):\n",
    "    assert len(idx) < 2, 'one image at a time'\n",
    "    color_map = 'viridis' if args.data_name == 'Wind' else 'inferno'\n",
    "    set_random_seed(666)\n",
    "\n",
    "    # generate fake images\n",
    "    hires, lores, fake = pred_img(args, dataset, idx, curr_scale, g_ema, ncand)\n",
    "\n",
    "    subplot_size = 6\n",
    "    images_num = ncand + 2  # ncand + LR + GT\n",
    "    fontsize, fontsize_xlab = 30, 30\n",
    "    rows, cols = args.channel, images_num + 1  # colorbar\n",
    "    image_size = 8*curr_scale # start from 8x8\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * subplot_size, rows * subplot_size))\n",
    "    gs = gridspec.GridSpec(\n",
    "        rows,\n",
    "        cols,\n",
    "        width_ratios=[1 for _ in range(images_num)] + [0.05],\n",
    "        height_ratios=[1 for _ in range(args.channel)]\n",
    "    )\n",
    "\n",
    "    for c in range(args.channel):\n",
    "        if args.data_name == 'Wind':\n",
    "            unit = '$m/s$'\n",
    "            ylab = 'V' if c else 'U'\n",
    "        else:\n",
    "            unit = '$W/m^2$'\n",
    "            ylab ='DHI' if c else 'DNI'\n",
    "\n",
    "        vmin0, vmax0 = (hires[c, :].min(), hires[c, :].max())\n",
    "\n",
    "        # input lr\n",
    "        ax_lr = fig.add_subplot(gs[c, 0])\n",
    "        ax_lr.imshow(lores[c, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "        ax_lr.set_ylabel(ylab, fontsize=fontsize_xlab)\n",
    "\n",
    "        # model outputs\n",
    "        for s in range(ncand):\n",
    "            ax = fig.add_subplot(gs[c, s + 1])\n",
    "            ax.imshow(\n",
    "                fake[c, :, image_size * s: image_size * (s + 1)],\n",
    "                vmin=vmin0,\n",
    "                vmax=vmax0,\n",
    "                cmap=color_map\n",
    "            )\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            if c == 0:\n",
    "                ax.set_title(\"$z\\sim\\mathcal{N}(0,\"+str(int((s/(ncand-1))**2))+\")$\",\n",
    "                    fontsize=fontsize\n",
    "                )\n",
    "\n",
    "        # ground truth\n",
    "        ax_hr = fig.add_subplot(gs[c, images_num - 1])\n",
    "        im = ax_hr.imshow(hires[c, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "\n",
    "        # colorbar\n",
    "        cbar = fig.colorbar(im, cax=fig.add_subplot(gs[c, images_num]))\n",
    "        cbar.ax.tick_params(labelsize=fontsize_xlab, length=10)\n",
    "        for t in cbar.ax.get_yticklabels():\n",
    "            t.set_horizontalalignment('right')\n",
    "            t.set_x(4)\n",
    "        cbar.set_label(label=unit, size=fontsize_xlab)\n",
    "\n",
    "        # set axis\n",
    "        ax_lr.set(xticks=[], yticks=[])\n",
    "        ax_hr.set(xticks=[], yticks=[])\n",
    "\n",
    "        # set titles\n",
    "        if c == 0:\n",
    "            ax_lr.set_title('LR', fontsize=fontsize)\n",
    "            ax_hr.set_title('Ground Truth', {'fontsize': fontsize})\n",
    "    plt.subplots_adjust(wspace=0, hspace=0.2, right=0.8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_preds_samples(args, g_ema, dataset, curr_scale:int, std:float=1.0, sample_num:int=50, plot_samples:int=3, idx:list=[0]):\n",
    "    \"\"\"\n",
    "    Plot several samples as well the mean and std of model predictions for a single test image.\n",
    "    \"\"\"\n",
    "    assert len(idx) < 2, 'one test image at a time'\n",
    "    assert sample_num >= plot_samples, 'sample_num should be greater or equal to plot_samples'\n",
    "    color_map = 'viridis' if args.data_name == 'Wind' else 'inferno'\n",
    "    set_random_seed(666)\n",
    "\n",
    "    # load data\n",
    "    device=torch.device(\"cuda\")\n",
    "    samples_list = [dataset[i] for i in idx]\n",
    "    x = torch.stack(samples_list).to(device)\n",
    "    lores = upscale(x, args.max_scale)\n",
    "    hires = upscale(x, args.max_scale // curr_scale)\n",
    "    hires = normalize(hires, args.train_mean, args.train_std, True).cpu().squeeze()\n",
    "\n",
    "    # generate fake samples\n",
    "    n, _, h, w = lores.shape\n",
    "    eps_size = [n, args.noise_dim, h, w]\n",
    "    fake = torch.empty((sample_num, args.channel, h * curr_scale, w * curr_scale))\n",
    "    with torch.no_grad():\n",
    "        for i in range(sample_num):\n",
    "            fake[i] = g_ema(lores, torch.normal(0, std, eps_size, device=device), curr_scale, 1)\n",
    "            fake[i] = normalize(fake[i], args.train_mean, args.train_std, True) # back2raw\n",
    "    lores = downscale(upscale(hires, curr_scale), curr_scale).cpu().squeeze()\n",
    "\n",
    "    # plot\n",
    "    subplot_size = 6\n",
    "    images_num = 4+plot_samples  # LR + 3 samples + mean + std + GT\n",
    "    rows, cols = args.channel, images_num + 1  # colorbar\n",
    "    fontsize, fontsize_xlab = 30, 30\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * subplot_size, rows * subplot_size))\n",
    "    gs = gridspec.GridSpec(rows, cols,\n",
    "        width_ratios=[1 for _ in range(images_num)] + [0.05],\n",
    "        height_ratios=[1 for _ in range(args.channel)]\n",
    "    )\n",
    "\n",
    "    for c in range(args.channel):\n",
    "        if args.data_name == 'Wind':\n",
    "            unit = '$m/s$'\n",
    "            ylab = 'V' if c else 'U'\n",
    "        else:\n",
    "            unit = '$W/m^2$'\n",
    "            ylab ='DHI' if c else 'DNI'\n",
    "\n",
    "        vmin0, vmax0 = (hires[c, :].min(), hires[c, :].max())\n",
    "\n",
    "        # real_lr\n",
    "        ax_lr = fig.add_subplot(gs[c, 0])\n",
    "        ax_lr.imshow(lores[c, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "        ax_lr.set_ylabel(ylab, fontsize=fontsize_xlab)\n",
    "\n",
    "        for i in range(plot_samples):\n",
    "            ax = fig.add_subplot(gs[c, i + 1])\n",
    "            ax.imshow(fake[i, c, :, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            if c == 0:\n",
    "                ax.set_title(f\"Sample {i+1}\", fontsize=fontsize)\n",
    "\n",
    "        ax_mean = fig.add_subplot(gs[c, 1+plot_samples])\n",
    "        ax_mean.imshow(\n",
    "            fake[:, c, :, :].mean(0),\n",
    "            vmin=vmin0,\n",
    "            vmax=vmax0,\n",
    "            cmap=color_map\n",
    "        )\n",
    "\n",
    "        ax_std = fig.add_subplot(gs[c, 2+plot_samples])\n",
    "        ax_std.imshow(fake[:, c, :, :].std(0), cmap=\"gray\")\n",
    "\n",
    "        # real_hr\n",
    "        ax_hr = fig.add_subplot(gs[c, 3+plot_samples])\n",
    "        im = ax_hr.imshow(hires[c, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "\n",
    "        # colorbar\n",
    "        cbar = fig.colorbar(im, cax=fig.add_subplot(gs[c, images_num]))\n",
    "        cbar.ax.tick_params(labelsize=fontsize_xlab, length=10)\n",
    "        for t in cbar.ax.get_yticklabels():\n",
    "            t.set_horizontalalignment('right')\n",
    "            t.set_x(4)\n",
    "        cbar.set_label(label=unit, size=fontsize_xlab)\n",
    "\n",
    "        # set axis\n",
    "        ax_lr.set(xticks=[], yticks=[])\n",
    "        ax_mean.set(xticks=[], yticks=[])\n",
    "        ax_std.set(xticks=[], yticks=[])\n",
    "        ax_hr.set(xticks=[], yticks=[])\n",
    "\n",
    "        # set titles\n",
    "        if c == 0:\n",
    "            ax_lr.set_title('LR', fontsize=fontsize)\n",
    "            ax_mean.set_title(\"Mean\", fontsize=fontsize)\n",
    "            ax_std.set_title(\"Standard deviation\", fontsize=fontsize)\n",
    "            ax_hr.set_title('Ground Truth', {'fontsize': fontsize})\n",
    "    plt.subplots_adjust(wspace=0, hspace=0.2, right=0.8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_preds_allScales(args, dataset, idx:list=[0]):\n",
    "    \"\"\"\n",
    "    Plot the predictions at all scales for a single test image.\n",
    "    \"\"\"\n",
    "    assert len(idx) < 2, 'one test image at a time'\n",
    "    color_map = 'viridis' if args.data_name == 'Wind' else 'inferno'\n",
    "\n",
    "    fake_list = []\n",
    "    for scale in [4, 8, 16, 32, 64]:\n",
    "        hires, lores, fake = pred_img(args, dataset, idx, scale, load_gen(args, scale), ncand=1)\n",
    "        fake_list.append(fake)\n",
    "    lores, hires = lores.cpu().squeeze(), hires.cpu().squeeze()\n",
    "\n",
    "    subplot_size = 6\n",
    "    images_num = 7  # LR + 4x + 8x + 16x + 32x + 64x + GT\n",
    "    rows, cols = args.channel, images_num + 1  # colorbar\n",
    "    fontsize, fontsize_xlab = 30, 30\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * subplot_size, rows * subplot_size))\n",
    "    gs = gridspec.GridSpec(rows, cols,\n",
    "        width_ratios=[1 for _ in range(images_num)] + [0.05],\n",
    "        height_ratios=[1 for _ in range(args.channel)]\n",
    "    )\n",
    "\n",
    "    for c in range(args.channel):\n",
    "        if args.data_name == 'Wind':\n",
    "            unit = '$m/s$'\n",
    "            ylab = 'V' if c else 'U'\n",
    "        else:\n",
    "            unit = '$W/m^2$'\n",
    "            ylab ='DHI' if c else 'DNI'\n",
    "\n",
    "        vmin0, vmax0 = (hires[c, :].min(), hires[c, :].max())\n",
    "\n",
    "        # real_lr\n",
    "        ax_lr = fig.add_subplot(gs[c, 0])\n",
    "        ax_lr.imshow(lores[c, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "        ax_lr.set_ylabel(ylab, fontsize=fontsize_xlab)\n",
    "\n",
    "        # model outputs\n",
    "        for s, scale_title in enumerate([r\"$4\\times$ SR\", r\"$8\\times$ SR\", r\"$16\\times$ SR\", r\"$32\\times$ SR\", r\"$64\\times$ SR\"]):\n",
    "            ax = fig.add_subplot(gs[c, s + 1])\n",
    "            ax.imshow(\n",
    "                fake_list[s][c, :, :],\n",
    "                vmin=vmin0,\n",
    "                vmax=vmax0,\n",
    "                cmap=color_map\n",
    "            )\n",
    "            ax.set(xticks=[], yticks=[])\n",
    "            if c == 0:\n",
    "                ax.set_title(scale_title, fontsize=fontsize)\n",
    "\n",
    "        # real_hr\n",
    "        ax_hr = fig.add_subplot(gs[c, images_num - 1])\n",
    "        im = ax_hr.imshow(hires[c, :], vmin=vmin0, vmax=vmax0, cmap=color_map)\n",
    "\n",
    "        # colorbar\n",
    "        cbar = fig.colorbar(im, cax=fig.add_subplot(gs[c, images_num]))\n",
    "        cbar.ax.tick_params(labelsize=fontsize_xlab, length=10)\n",
    "        for t in cbar.ax.get_yticklabels():\n",
    "            t.set_horizontalalignment('right')\n",
    "            t.set_x(4)\n",
    "        cbar.set_label(label=unit, size=fontsize_xlab)\n",
    "\n",
    "        # set axis\n",
    "        ax_lr.set(xticks=[], yticks=[])\n",
    "        ax_hr.set(xticks=[], yticks=[])\n",
    "\n",
    "        # set titles\n",
    "        if c == 0:\n",
    "            ax_lr.set_title('LR', fontsize=fontsize)\n",
    "            ax_hr.set_title('Ground Truth', fontsize=fontsize)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Download pre-trained weights and setup folders\n",
    "folder = {\n",
    "    \"Wind\": \"results/Wind/Wind_bs32_epoch20_lr3e-3_64X\",\n",
    "    \"Solar\":\"results/Solar/Solar_bs1_epoch15_lr4e-3_64X\"\n",
    "}\n",
    "\n",
    "# Download pre-trained weights from Google Drive\n",
    "!gdown --folder 1cyXKsZJjeYMR_KE-nLTyB21Zt6CdF-wh -O /content/LAG_Climate/results/Wind/Wind_bs32_epoch20_lr3e-3_64X\n",
    "!gdown --folder 1q_uNK3cSqLWqDJ5xVlRTxN9fHcTEZ1av -O /content/LAG_Climate/results/Solar/Solar_bs1_epoch15_lr4e-3_64X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generate HR images at all downscaling scales\n",
    "data_type = \"Wind\" # @param [\"Wind\",\"Solar\"]\n",
    "\n",
    "args, _ = get_config_from_json(f\"{folder[data_type]}/args/args.json\")\n",
    "dataset, args = load_dataset(args)\n",
    "plot_preds_allScales(args, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generate HR images from chosen downscaling scale and data type\n",
    "data_type = \"Wind\" # @param [\"Wind\",\"Solar\"]\n",
    "test_scale = 4 # @param [\"4\",\"8\",\"16\",\"32\",\"64\"] {\"type\":\"raw\"}\n",
    "\n",
    "args, _ = get_config_from_json(f\"{folder[data_type]}/args/args.json\")\n",
    "dataset, args = load_dataset(args)\n",
    "g_ema = load_gen(args, test_scale)\n",
    "plot_preds(args, g_ema, dataset, test_scale, ncand=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Sample images from chosen downscaling scale and data type\n",
    "data_type = \"Wind\" # @param [\"Wind\",\"Solar\"]\n",
    "test_scale = 4 # @param [\"4\",\"8\",\"16\",\"32\",\"64\"] {\"type\":\"raw\"}\n",
    "noise_std = 1.0 # @param {\"type\":\"number\", \"placeholder\":\"1.0\"}\n",
    "num_samples = 50 # @param {\"type\":\"integer\", \"placeholder\":\"50\"}\n",
    "num_plot_samples = 3 # @param {\"type\":\"integer\", \"placeholder\":\"3\"}\n",
    "\n",
    "args, _ = get_config_from_json(f\"{folder[data_type]}/args/args.json\")\n",
    "dataset, args = load_dataset(args)\n",
    "g_ema = load_gen(args, test_scale)\n",
    "plot_preds_samples(args, g_ema, dataset, test_scale, noise_std, num_samples, num_plot_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.13.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
